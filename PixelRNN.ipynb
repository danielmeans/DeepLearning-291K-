{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PixelRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielmeans/DeepLearning-291K-/blob/master/PixelRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkleuIuSYBRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly-gpu-2.0-preview\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_wt-k_tZToi",
        "colab_type": "code",
        "outputId": "5e2cbc2b-d807-401b-fd7a-d94e3c2ff951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train_), (x_test, y_test_) = cifar10.load_data()\n",
        "x_train_n = x_train.astype('float32') / 255\n",
        "x_test_n = x_test.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqvpFez7bgbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "height, width, channels, flat_dim = 32, 32, 3, 3072\n",
        "\n",
        "#For each pixel in Each image, construct vectors of neightboring pixels\n",
        "# Flatten each channel into a 1024 length 1-dimensional vector\n",
        "def get_pixel_neighbor_vector(x_train):\n",
        "  image = x_train[0]\n",
        "  image_r = np.reshape(image, (3, -1))\n",
        "  #Number of preceding pixels to use when predicting current pixel\n",
        "  num_neighbors = 19\n",
        "  #tensor to store neighboring pixels of each pixel in an image\n",
        "  neighbor_tensor = []\n",
        "  for channel in range(channels):\n",
        "    per_channel_tensor = []\n",
        "    for index in range(flat_dim):\n",
        "      #determine how much padding to add to the neighboring pixels, for the first 19 pixels\n",
        "      start = max(index - num_neighbors, 0)\n",
        "      padding_length = num_neighbors - (index - start)\n",
        "      padding = np.array([0] * padding_length)\n",
        "      #append place holders for red, green channels computed for these pixels\n",
        "      if channel == 1:\n",
        "        red_green = np.concatenate((np.array(image_r[0][index: index + 1 ]), np.array([0])), axis=0)\n",
        "      elif channel == 2:\n",
        "        red_green = np.concatenate((np.array(image_r[0][index: index + 1]), np.array(image_r[1][index: index + 1])), axis=0)\n",
        "      else:\n",
        "        red_green = np.array([0] * 2)\n",
        "      neighbors = np.concatenate((padding, image_r[channel][start:index], red_green), axis=0)\n",
        "      per_channel_tensor.append(neighbors)\n",
        "    neighbor_tensor.append(per_channel_tensor)\n",
        "  return neighbor_tensor\n",
        "def get_pixel_neighbor_vector_flat(image):\n",
        "  #Flatten image (32 * 32 * 3) --> 3072\n",
        "  image_r = np.reshape(image,  (-1))\n",
        "  #Number of preceding pixels to use when predicting current pixel\n",
        "  num_neighbors = 21\n",
        "  #tensor to store neighboring pixels of each pixel in an image\n",
        "  neighbor_tensor = []\n",
        "  for index in range(flat_dim):\n",
        "    #determine how much padding to add to the neighboring pixels, for the first 19 pixels\n",
        "    start = max(index - num_neighbors, 0)\n",
        "    padding_length = num_neighbors - (index - start)\n",
        "    padding = np.array([0] * padding_length)\n",
        "    neighbors = np.concatenate((padding, image_r[start:index]), axis=0)\n",
        "    neighbor_tensor.append(neighbors)\n",
        "  return np.array(neighbor_tensor).astype('float32')\n",
        "\n",
        "def get_pixel_neighbor_vector_2(image):\n",
        "  #Number of preceding pixels to use when predicting current pixel\n",
        "  num_neighbors = 6\n",
        "  #tensor to store neighboring pixels of each pixel in an image\n",
        "  neighbor_tensor = []\n",
        "  for row in range(len(image)):\n",
        "    for col in range(len(image[0])):\n",
        "      #determine how much padding to add to the neighboring pixels, for the first 19 pixels\n",
        "      start = max(col - num_neighbors, 0)\n",
        "      padding_length = num_neighbors - (col - start)\n",
        "      padding = np.array([0] * padding_length)\n",
        "      for pixel in range(start, col):\n",
        "        for channel in range(len(pixel)):\n",
        "          \n",
        "          #append place holders for red, green channels computed for these pixels\n",
        "          if channel_idx == 1:\n",
        "            red_green = np.concatenate((np.array(image[row][col][channel_idx - 1]), np.array([0])), axis=0)\n",
        "          elif channel_idx == 2:\n",
        "            red_green = np.concatenate((np.array(image[row][col][channel_idx -2 ]), np.array(image[1][col: col + 1][channel_idx -2])), axis=0)\n",
        "          else:\n",
        "            red_green = np.array([0] * 2)\n",
        "          \n",
        "        \n",
        "      neighbors = np.concatenate((padding, image[channel_idx][start:col], red_green), axis=0)\n",
        "  return neighbor_tensor\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsgQwqO-dlqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "image_r = np.reshape(x_train[0], (32, 96))\n",
        "first_row = image_r[1]\n",
        "\n",
        "def get_one_hot_vectors(image):\n",
        "  while True:\n",
        "    images=[]\n",
        "    for row in range(height):\n",
        "      cur_row = image[row]\n",
        "      one_hot_row = []\n",
        "      for pix in cur_row:\n",
        "        pixel = []\n",
        "        for pix_channel in pix:\n",
        "          one_hot_pix_channel = [0] * 256\n",
        "          one_hot_pix_channel[pix_channel] = 1\n",
        "          pixel.append(one_hot_pix_channel)\n",
        "        one_hot_row.append(pixel)\n",
        "      images.append(one_hot_row)\n",
        "    yield np.array(images).astype('int32')\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxJ7hB370whK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pixel by pixel rnn\n",
        "from numpy import array\n",
        "# define input sequence\n",
        "for i in range(len(x_train()): \n",
        "  neighbors = get_pixel_neighbor_vector_flat(x_train_n[i])\n",
        "  one_hot_image_gen = get_one_hot_vectors(x_train[i])\n",
        "  one_hot_image = next(one_hot_image_gen)\n",
        "  for row in range(len(one_hot_image)):\n",
        "    for col in range(len(one_hot_image[0])):\n",
        "      for channel in range(len(one_hot_image[0][0])):\n",
        "        neighbor_idx = row * 32 + col * 3 + channel\n",
        "        seq_in = neighbors[neighbor_idx]\n",
        "        # reshape input into [samples, timesteps, features]\n",
        "        n_in = len(seq_in)\n",
        "        seq_in = seq_in.reshape((1, n_in, 1))\n",
        "        # prepare output sequence\n",
        "        seq_out = one_hot_image[row][col][channel]\n",
        "        n_out = len(seq_out)\n",
        "        seq_out = seq_out.reshape((1, n_out))\n",
        "        #define model\n",
        "        model = tf.keras.models.Sequential()\n",
        "        tf.keras.layers.Dense(units=512, activation=tf.nn.relu, use_bias=True, input_shape=(n_in, 1))\n",
        "        model.add(tf.keras.layers.LSTM(512, activation='relu', use_bias=True))\n",
        "        model.add(tf.keras.layers.RepeatVector(n_out))\n",
        "        model.add(tf.keras.layers.LSTM(512, activation='relu',  use_bias=True))\n",
        "        #model.add(tf.keras.layers.Dense(1))\n",
        "        model.add(tf.keras.layers.Dense(256, activation='softmax'))\n",
        "        with tf.device('/device:GPU:0'):\n",
        "\n",
        "          model.compile(optimizer='adam', loss=tf.nn.softmax_cross_entropy_with_logits)\n",
        "\n",
        "          # fit model\n",
        "          model.fit(seq_in, seq_out, epochs=100, verbose=1)\n",
        "          # demonstrate prediction\n",
        "          yhat = model.predict(seq_in, verbose=0)\n",
        "          print(yhat)\n",
        "          print(seq_out)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6Zj3VI3ncjm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f02813bf-c1c2-44db-9344-eec79efda309"
      },
      "source": [
        "###Row LSTM\n",
        "#define model\n",
        "for image in x_train:\n",
        "  for row in image:\n",
        "    seq_in = row\n",
        "    # reshape input into [samples, timesteps, features]\n",
        "    n_in = len(seq_in)\n",
        "    seq_in = seq_in.reshape((1, n_in, 1))\n",
        "    # prepare output sequence\n",
        "    seq_out = seq_in[:,:,:]\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      model =  tf.keras.models.Sequential()\n",
        "      model.add(tf.keras.layers.LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
        "      model.add(tf.keras.layers.RepeatVector(n_in))\n",
        "      model.add(tf.keras.layers.LSTM(100, activation='relu', return_sequences=True))\n",
        "      model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)))\n",
        "      #compile model\n",
        "      model.compile(optimizer='adam', loss=tf.nn.softmax_cross_entropy_with_logits)\n",
        "\n",
        "      # fit model\n",
        "      model.fit(seq_in, seq_out, epochs=100, verbose=1)\n",
        "      # demonstrate prediction\n",
        "      yhat = model.predict(seq_in, verbose=0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1 samples\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 2s 2s/sample - loss: 5.5452\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 313ms/sample - loss: 5.5452\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 296ms/sample - loss: 5.5452\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 294ms/sample - loss: 5.5452\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 287ms/sample - loss: 5.5451\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 299ms/sample - loss: 5.5451\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 301ms/sample - loss: 5.5451\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 295ms/sample - loss: 5.5451\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 317ms/sample - loss: 5.5451\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 296ms/sample - loss: 5.5451\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 284ms/sample - loss: 5.5451\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 307ms/sample - loss: 5.5451\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 310ms/sample - loss: 5.5451\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 292ms/sample - loss: 5.5451\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 293ms/sample - loss: 5.5451\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 306ms/sample - loss: 5.5451\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 306ms/sample - loss: 5.5451\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 293ms/sample - loss: 5.5450\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 287ms/sample - loss: 5.5450\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 304ms/sample - loss: 5.5450\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 280ms/sample - loss: 5.5450\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 282ms/sample - loss: 5.5450\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 300ms/sample - loss: 5.5450\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 277ms/sample - loss: 5.5450\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 308ms/sample - loss: 5.5450\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 307ms/sample - loss: 5.5450\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 306ms/sample - loss: 5.5450\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 281ms/sample - loss: 5.5450\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 298ms/sample - loss: 5.5450\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 306ms/sample - loss: 5.5450\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 308ms/sample - loss: 5.5449\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 317ms/sample - loss: 5.5449\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 303ms/sample - loss: 5.5449\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 307ms/sample - loss: 5.5449\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 325ms/sample - loss: 5.5449\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 296ms/sample - loss: 5.5449\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 291ms/sample - loss: 5.5449\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 280ms/sample - loss: 5.5449\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 296ms/sample - loss: 5.5449\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 314ms/sample - loss: 5.5449\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 293ms/sample - loss: 5.5449\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 284ms/sample - loss: 5.5449\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 291ms/sample - loss: 5.5448\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 284ms/sample - loss: 5.5448\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 298ms/sample - loss: 5.5448\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 281ms/sample - loss: 5.5448\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 304ms/sample - loss: 5.5448\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 305ms/sample - loss: 5.5448\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 312ms/sample - loss: 5.5448\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 300ms/sample - loss: 5.5448\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 302ms/sample - loss: 5.5448\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 303ms/sample - loss: 5.5448\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 279ms/sample - loss: 5.5448\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 305ms/sample - loss: 5.5447\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 299ms/sample - loss: 5.5447\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 297ms/sample - loss: 5.5447\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 310ms/sample - loss: 5.5447\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 294ms/sample - loss: 5.5447\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 285ms/sample - loss: 5.5447\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 281ms/sample - loss: 5.5447\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 306ms/sample - loss: 5.5447\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 289ms/sample - loss: 5.5447\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 296ms/sample - loss: 5.5447\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 311ms/sample - loss: 5.5447\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 304ms/sample - loss: 5.5446\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 282ms/sample - loss: 5.5446\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 284ms/sample - loss: 5.5446\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 289ms/sample - loss: 5.5446\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 293ms/sample - loss: 5.5446\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 302ms/sample - loss: 5.5446\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 317ms/sample - loss: 5.5446\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 301ms/sample - loss: 5.5446\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 301ms/sample - loss: 5.5446\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 299ms/sample - loss: 5.5446\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 296ms/sample - loss: 5.5446\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 287ms/sample - loss: 5.5445\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 285ms/sample - loss: 5.5445\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 307ms/sample - loss: 5.5445\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 298ms/sample - loss: 5.5445\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 298ms/sample - loss: 5.5445\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 305ms/sample - loss: 5.5445\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 288ms/sample - loss: 5.5445\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 306ms/sample - loss: 5.5445\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 284ms/sample - loss: 5.5445\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 307ms/sample - loss: 5.5445\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 285ms/sample - loss: 5.5445\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 290ms/sample - loss: 5.5444\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 316ms/sample - loss: 5.5444\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 309ms/sample - loss: 5.5444\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 297ms/sample - loss: 5.5444\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 310ms/sample - loss: 5.5444\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 299ms/sample - loss: 5.5444\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 287ms/sample - loss: 5.5444\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 305ms/sample - loss: 5.5444\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 312ms/sample - loss: 5.5444\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 312ms/sample - loss: 5.5444\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 282ms/sample - loss: 5.5443\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 300ms/sample - loss: 5.5443\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 277ms/sample - loss: 5.5443\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 295ms/sample - loss: 5.5443\n",
            "[[0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00478162\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282 0.00390282 0.00390282\n",
            "  0.00390282 0.00390282 0.00390282 0.00390282]]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDDLF2i7oymb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}